{"id":"furman-19n","title":"Add proxy support (HTTP/SOCKS)","description":"Allow S3 connections through HTTP or SOCKS proxies. S3 Browser and CloudBerry support this.\n\n## Scope\n- Configure HTTP/HTTPS proxy in connection settings\n- Configure SOCKS5 proxy\n- Proxy authentication (username/password)\n- Per-connection proxy settings\n- System proxy auto-detection option\n\n## Backend\n- Pass proxy configuration to the AWS SDK HTTP client\n- aws-smithy-http supports custom HTTP connectors with proxy settings via hyper\n\n## Notes\n- Important for enterprise environments behind corporate firewalls\n- Tauri's HTTP client may also need proxy configuration for presigned URL fetching","status":"open","priority":4,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:04:26Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T13:04:26Z"}
{"id":"furman-2bq","title":"Create Cyberduck S3 profile import script","description":"Node.js ESM script that clones iterate-ch/profiles, extracts S3 profiles, groups by provider family, outputs JSON","status":"closed","priority":2,"issue_type":"task","owner":"fenio@debian.org","created_at":"2026-02-26T18:10:20Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T18:16:51Z","closed_at":"2026-02-26T18:16:51Z","close_reason":"Script generates 38 providers with 179 regional endpoints from Cyberduck profiles"}
{"id":"furman-2f5","title":"Add drag-and-drop support for file uploads and downloads","description":"Implement drag-and-drop file transfer between the OS file manager (Finder) and Furman's S3 panel. This is table-stakes UX that every major S3 client (Cyberduck, S3 Browser, Transmit, CloudBerry, WinSCP) supports.\n\n## Scope\n\n- Drag from Finder to S3 panel: Upload files/folders to the current S3 prefix\n- Drag from S3 panel to Finder: Download files/folders to the drop target\n- Drag between panels: If both panels are S3, perform server-side copy; if one is local, upload/download accordingly\n\n## Notes\n\n- Tauri supports drag-and-drop events via the window's onDragDropEvent or HTML5 drag/drop APIs\n- Should integrate with the existing transfer queue (multipart, pause/resume, bandwidth throttling)\n- Show visual drop target indicator when dragging over a valid panel","status":"closed","priority":2,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T12:58:32Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T13:43:32Z","closed_at":"2026-02-26T13:43:32Z","close_reason":"Implemented drag-and-drop improvements: migrated OS drop to transfer queue (enqueue), added tauri-plugin-drag for native drag-out to Finder, added mousedown+mousemove gesture detection for local and S3 file drag-out"}
{"id":"furman-36a","title":"Add sorting options for file listings","description":"Add sorting options for S3 object listings. Every major S3 client supports this.\n\n## Scope\n- Sort by name (ascending/descending)\n- Sort by size\n- Sort by last modified date\n- Sort by storage class\n- Persist sort preference per panel/session\n- Visual indicator showing current sort column and direction\n\n## Notes\n- S3 ListObjectsV2 always returns objects in lexicographic order by key\n- Sorting must be done client-side after fetching the listing\n- Should work with the existing virtual folder hierarchy (folders first, then files)","status":"closed","priority":2,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:03:42Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T14:18:49Z","closed_at":"2026-02-26T14:18:49Z","close_reason":"Implemented storage_class sort field, S3 column sorts correctly, and sort preferences persist across restarts"}
{"id":"furman-3ic","title":"Add Web Identity Federation (OIDC) authentication","description":"Support login via OpenID Connect identity providers (Google, Azure AD, etc.) using AssumeRoleWithWebIdentity STS API. Only Cyberduck has this among desktop S3 clients.\n\n## Scope\n- Configure OIDC provider (issuer URL, client ID)\n- Browser-based OAuth2/OIDC login flow\n- Exchange OIDC token for temporary AWS credentials via STS\n- Support Google and Azure AD as identity providers\n- Refresh tokens automatically before expiry\n\n## Notes\n- Uses AssumeRoleWithWebIdentity STS API\n- Requires an IAM role with a trust policy for the OIDC provider\n- Tauri can handle the OAuth redirect flow via a local callback\n- Would make Furman one of few desktop S3 clients with OIDC support","status":"open","priority":4,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:04:16Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T13:04:16Z"}
{"id":"furman-3oo","title":"Add MFA Delete support for versioned objects","description":"Add support for MFA Delete, which requires multi-factor authentication to permanently delete versioned objects. Cyberduck supports this.\n\n## Scope\n- Enable/disable MFA Delete in bucket versioning configuration\n- Prompt for MFA token when deleting versioned objects in MFA-protected buckets\n- Display MFA Delete status in bucket properties\n\n## Notes\n- MFA Delete can only be enabled by the root account (not IAM users)\n- Requires x-amz-mfa header with the MFA device serial and token code\n- Protects against accidental or malicious permanent deletion of versioned data","status":"open","priority":3,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:04:11Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T13:04:11Z"}
{"id":"furman-3xq","title":"Add anonymous / public bucket browsing","description":"Allow connecting to public S3 buckets without credentials. Cyberduck supports anonymous login for browsing public buckets.\n\n## Scope\n- Option to connect without credentials in S3ConnectDialog\n- Pass no credentials to build_s3_client (use no_credentials provider instead of default chain)\n- Handle graceful errors when trying write operations on read-only public buckets\n\n## Backend\n- Update build_s3_client to support an explicit anonymous/no-credentials mode\n- Use aws_credential_types::provider::SharedCredentialsProvider with no_credentials()\n\n## Notes\n- Public buckets are increasingly rare due to AWS Block Public Access defaults, but still used for open data (e.g., AWS Open Data, NOAA, Landsat)\n- Should clearly indicate in the UI that the connection is anonymous/read-only","status":"closed","priority":2,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:03:48Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T18:58:05Z","closed_at":"2026-02-26T18:58:05Z","close_reason":"Implemented anonymous/public bucket browsing: backend no_credentials() support, frontend checkbox with conditional credential fields, sidebar reconnect handling"}
{"id":"furman-4q1","title":"Add folder sync between local filesystem and S3","description":"Implement local-to-S3 and S3-to-local folder synchronization. This is a heavily requested feature in S3 clients -- Transmit, CloudBerry, and S3 Browser all offer it.\n\n## Scope\n- Local to S3 sync: Upload new/changed files from a local directory to an S3 prefix\n- S3 to Local sync: Download new/changed objects from an S3 prefix to a local directory\n- Comparison modes: Compare by size + last modified date; optionally by ETag/checksum\n- Preview mode: Show a diff/plan of what would be transferred before executing\n- Filters: Include/exclude patterns (e.g., ignore .DS_Store, node_modules/)\n- Delete handling: Option to delete files at destination that don't exist at source (with confirmation)\n\n## Notes\n- Should integrate with the existing transfer queue for actual file transfers\n- Consider a dry-run mode that shows what would change without transferring\n- Bidirectional sync is complex (conflict resolution) -- start with one-directional sync first\n- S3-to-S3 sync (between buckets/prefixes) would be a natural follow-up","status":"closed","priority":2,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T12:58:48Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T20:23:32Z","closed_at":"2026-02-26T20:23:32Z","close_reason":"All scope items implemented: localâ†”S3 sync, size+mtime and checksum comparison modes, exclude pattern filters, preview diff, and delete handling"}
{"id":"furman-5dg","title":"Add S3 event notification configuration","description":"Allow configuring S3 event notifications (SNS, SQS, Lambda triggers) from the bucket properties dialog. No desktop S3 client currently offers this -- would be a unique feature.\n\n## Scope\n- View existing notification configurations on a bucket\n- Add/edit/delete notification rules\n- Support destination types: SNS topic, SQS queue, Lambda function\n- Configure event filters (prefix, suffix) and event types (s3:ObjectCreated:*, s3:ObjectRemoved:*, etc.)\n- EventBridge integration toggle\n\n## Backend\n- New Tauri commands: s3_get_bucket_notification, s3_put_bucket_notification\n- Uses GetBucketNotificationConfiguration / PutBucketNotificationConfiguration APIs\n\n## Notes\n- Destinations must already exist and have proper permissions (resource policies)\n- Consider listing available SNS topics / SQS queues / Lambda functions via their respective APIs\n- This is a Tier 4 feature -- no desktop client does this yet","status":"open","priority":4,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:04:22Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T13:04:22Z"}
{"id":"furman-5pt","title":"Add SSE-KMS key selection with key listing","description":"Enhance the encryption configuration to list available KMS keys and let users pick from a dropdown. Cyberduck does this natively.\n\n## Scope\n- List available KMS keys via AWS KMS ListKeys/ListAliases API\n- Show key alias and ID in a dropdown when configuring SSE-KMS\n- Allow specifying a custom KMS key ARN manually\n- Display the current KMS key in object/bucket properties\n\n## Backend\n- New Tauri command: s3_list_kms_keys (uses aws-sdk-kms crate)\n- Add KMS key ARN field to encryption configuration\n\n## Notes\n- Requires aws-sdk-kms as a new dependency\n- KMS keys are region-specific\n- The user's IAM policy must include kms:ListKeys and kms:ListAliases permissions","status":"closed","priority":3,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:04:03Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T14:41:50Z","closed_at":"2026-02-26T14:41:50Z","close_reason":"Implemented KMS key listing dropdown for SSE-KMS encryption"}
{"id":"furman-5ws","title":"Add checksum verification on upload/download","description":"Implement data integrity verification using checksums during transfers. Cyberduck offers configurable SHA-256 verification.\n\n## Scope\n- Calculate SHA-256 (or CRC32/CRC32C) checksum during upload and include in request\n- Verify checksum on download against the stored value\n- Support S3 additional checksums feature (x-amz-checksum-sha256, x-amz-checksum-crc32)\n- Option to enable/disable verification in preferences (adds CPU overhead)\n- Show verification status in transfer completion\n\n## Notes\n- S3 already returns ETag (MD5 for non-multipart) which can be used for basic verification\n- Additional checksums (SHA-256, CRC32, CRC32C) were added to S3 in 2022\n- For multipart uploads, each part has its own checksum\n- Consider making this opt-in since it adds CPU overhead on large files","status":"in_progress","priority":3,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:04:08Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T21:44:23Z"}
{"id":"furman-6f3","title":"Update s3-providers.ts with Cyberduck data and region support","description":"Add S3ProviderRegion type, regions/website fields, merge imported providers, expand endpoint patterns","status":"closed","priority":2,"issue_type":"task","owner":"fenio@debian.org","created_at":"2026-02-26T18:10:21Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T18:18:20Z","closed_at":"2026-02-26T18:18:20Z","close_reason":"Types extended, 38 Cyberduck providers merged with curated entries, 37 new endpoint patterns","dependencies":[{"issue_id":"furman-6f3","depends_on_id":"furman-2bq","type":"blocks","created_at":"2026-02-26T19:10:35Z","created_by":"Bartosz Fenski","metadata":"{}"}]}
{"id":"furman-77e","title":"Batch metadata and tag editing for multiple S3 objects","description":"When multiple S3 objects are selected and user presses F9/Cmd+I, open a batch edit dialog instead of single-object properties. Adds backend batch_put_object_metadata and batch_put_object_tags with progress/cancel, frontend dialog with Metadata and Tags tabs, progress bar, and results display.","status":"closed","priority":2,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T20:46:30Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T20:53:04Z","closed_at":"2026-02-26T20:53:04Z","close_reason":"Closed"}
{"id":"furman-7ot","title":"Add cross-region replication configuration","description":"Allow configuring S3 Cross-Region Replication (CRR) and Same-Region Replication (SRR) from bucket properties. S3 Browser is the only desktop client with this.\n\n## Scope\n- View existing replication rules on a bucket\n- Add/edit/delete replication rules\n- Configure destination bucket and region\n- Filter by prefix and tags\n- Replication options: storage class override, encryption, delete marker replication\n\n## Backend\n- New Tauri commands: s3_get_bucket_replication, s3_put_bucket_replication\n- Uses GetBucketReplication / PutBucketReplication APIs\n\n## Notes\n- Requires versioning enabled on both source and destination buckets\n- Requires an IAM role with replication permissions\n- Only replicates new objects after rule creation (not retroactive)","status":"open","priority":4,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:04:34Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T13:04:34Z"}
{"id":"furman-80i","title":"Add batch metadata and tag editing for multiple objects","description":"Allow editing metadata and tags on multiple selected objects at once. Cyberduck supports batch editing of headers.\n\n## Scope\n- Select multiple objects, right-click to edit metadata/tags\n- Apply the same metadata changes (Content-Type, Cache-Control, custom headers) to all selected objects\n- Apply the same tags to all selected objects\n- Show progress indicator for batch operations\n- Option to replace all tags or merge with existing\n\n## Notes\n- S3 does not have a batch metadata API -- must iterate and call PutObjectMetadata for each object (copy-in-place with new metadata)\n- For tags, call PutObjectTagging for each object\n- Consider a confirmation dialog showing how many objects will be affected","status":"closed","priority":2,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:03:52Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T21:43:45Z","closed_at":"2026-02-26T21:43:45Z","close_reason":"Implemented batch metadata and tag editing dialog with progress/cancel support"}
{"id":"furman-a61","title":"Add client-side encryption (encrypt before upload)","description":"Implement client-side encryption to encrypt files before uploading to S3. CloudBerry PRO and S3 Browser both offer this.\n\n## Scope\n- Password-based AES-256 encryption before upload\n- Transparent decryption on download (prompt for password)\n- Store encryption metadata as custom S3 headers (x-amz-meta-*) to identify encrypted objects\n- Visual indicator on encrypted objects in the file listing\n- Option to set encryption as default for a connection/bucket\n\n## Notes\n- Distinct from SSE (server-side encryption) which Furman already supports\n- Client-side encryption means the data is encrypted before it leaves the machine\n- Need to handle multipart uploads (encrypt each part)\n- Consider using a well-established encryption library (e.g., ring or aes-gcm crate)\n- Must handle key derivation properly (PBKDF2/Argon2 from password)","status":"closed","priority":3,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:03:58Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T16:06:41Z","closed_at":"2026-02-26T16:06:41Z","close_reason":"Implemented client-side encryption: AES-256-GCM + Argon2id crypto module with unit tests, metadata-based encryption detection, encrypted upload/download commands, password input dialog, per-profile encryption default, lock icon indicator in file listing"}
{"id":"furman-b5h","title":"Add bookmark / favorites for S3 paths","description":"Allow users to bookmark frequently accessed S3 paths (bucket + prefix) for quick navigation. Transmit has a Places bar, Cyberduck has rich bookmarks.\n\n## Scope\n- Bookmark current path (bucket/prefix) with a custom name\n- Favorites sidebar or dropdown for one-click navigation\n- Organize bookmarks (reorder, rename, delete)\n- Persist bookmarks across sessions\n- Keyboard shortcut to add/access bookmarks\n\n## Notes\n- Distinct from saved connections -- bookmarks are paths within a connection\n- Could integrate with the existing connection manager or be a separate feature\n- Consider supporting bookmark import/export","status":"closed","priority":3,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:04:32Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T15:03:54Z","closed_at":"2026-02-26T15:03:54Z","close_reason":"Implemented S3 path bookmarks in sidebar with auto-connect, Cmd+D shortcut, keyboard nav, and config persistence"}
{"id":"furman-bay","title":"Add CRC32C checksum verification for S3 uploads \u0026 downloads","description":"Add CRC32C integrity checking to all upload/download paths. Uploads: set checksum_algorithm(Crc32C) on put_object, create_multipart_upload, and upload_part. Downloads: set checksum_mode(Enabled), compute CRC32C incrementally, verify against returned value. Falls back to MD5/ETag for pre-CRC32C objects.","status":"closed","priority":2,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T21:54:26Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T22:10:55Z","closed_at":"2026-02-26T22:10:55Z","close_reason":"CRC32C checksum verification implemented for all S3 upload and download paths"}
{"id":"furman-dba","title":"Add S3 Select support for in-place querying of CSV/JSON/Parquet","description":"Implement S3 Select to let users run SQL queries on CSV, JSON, and Parquet files directly in S3 without downloading them. No desktop S3 client currently offers this -- it would be a unique selling point for Furman.\n\n## Scope\n- Query UI: SQL editor with syntax highlighting for writing SELECT queries\n- Input format configuration: CSV (delimiter, header row, comments), JSON (document vs. lines), Parquet\n- Output format: Display results in a table view; option to export as CSV/JSON\n- Compression support: GZIP, BZIP2, and uncompressed input\n- Progress reporting: S3 Select provides progress events -- show bytes scanned/processed\n\n## Backend\n- New Tauri command: s3_select_object_content\n- Uses SelectObjectContent API with InputSerialization, OutputSerialization, and Expression\n- Stream results back to frontend via Tauri events\n\n## Example Use Cases\n- Query a 10GB CSV log file for specific error codes without downloading\n- Extract specific fields from large JSON datasets\n- Preview Parquet data without any local tooling\n\n## Notes\n- S3 Select has a 256KB output limit per record\n- Not supported on Glacier/Deep Archive storage classes\n- Works on individual objects only (not across multiple files)\n- Consider offering query templates for common operations (COUNT, WHERE, LIMIT)","status":"open","priority":3,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T12:58:57Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T12:58:57Z"}
{"id":"furman-e0r","title":"Add searchable provider combobox and region selector to S3ConnectDialog","description":"Replace select with searchable combobox for 50+ providers, add region dropdown when provider has regions","status":"closed","priority":2,"issue_type":"task","owner":"fenio@debian.org","created_at":"2026-02-26T18:10:23Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T18:20:55Z","closed_at":"2026-02-26T18:20:55Z","close_reason":"Searchable provider combobox with keyboard nav, region preset dropdown with Custom option for manual entry","dependencies":[{"issue_id":"furman-e0r","depends_on_id":"furman-6f3","type":"blocks","created_at":"2026-02-26T19:10:36Z","created_by":"Bartosz Fenski","metadata":"{}"}]}
{"id":"furman-ezw","title":"Configurable encryption options","description":"Make encryption settings configurable per-profile: (1) Argon2id KDF params (memory/time/parallelism), (2) cipher choice (AES-256-GCM / ChaCha20-Poly1305), (3) auto-encrypt threshold (min file size, extension filter), (4) temp file cleanup behavior (secure wipe vs normal delete)","status":"closed","priority":2,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T16:17:22Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T16:31:30Z","closed_at":"2026-02-26T16:31:30Z","close_reason":"Implemented all 4 configurable encryption options: cipher choice, KDF params, auto-encrypt threshold, secure temp cleanup"}
{"id":"furman-j3x","title":"Add CloudFront distribution management","description":"Implement CloudFront CDN management as a natural extension of the existing S3 website hosting feature. Cyberduck is the only desktop client with comprehensive CloudFront support.\n\n## Scope\n- Create/delete CloudFront distributions for S3 buckets\n- Configure origins, default cache behavior, and custom error responses\n- Enable/disable distributions\n- Cache invalidation (invalidate specific paths or entire distribution)\n- Display distribution status (In Progress / Deployed)\n- Generate CloudFront URLs for objects\n- CNAME configuration\n- Distribution access logging\n\n## Backend\n- New Tauri commands using aws-sdk-cloudfront: s3_list_distributions, s3_create_distribution, s3_get_distribution, s3_update_distribution, s3_delete_distribution, s3_create_invalidation\n- New service module: src-tauri/src/cloudfront/\n\n## Notes\n- CloudFront is a separate AWS service (not S3 API) -- requires aws-sdk-cloudfront crate\n- Distribution creation/updates are async (take minutes to deploy globally)\n- Pairs naturally with the existing website hosting tab in S3PropertiesDialog\n- Consider adding a CloudFront tab to the bucket properties dialog","status":"open","priority":3,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T12:59:04Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T12:59:04Z"}
{"id":"furman-m2o","title":"Add S3 Inventory configuration","description":"Allow configuring S3 Inventory reports from bucket properties. No desktop S3 client currently offers this.\n\n## Scope\n- View existing inventory configurations\n- Create/edit/delete inventory configurations\n- Configure: destination bucket, frequency (daily/weekly), output format (CSV/ORC/Parquet)\n- Select optional fields (size, last modified, storage class, ETag, encryption status, etc.)\n- Filter by prefix\n\n## Backend\n- New Tauri commands: s3_list_bucket_inventory, s3_get_bucket_inventory, s3_put_bucket_inventory, s3_delete_bucket_inventory\n- Uses ListBucketInventoryConfigurations / GetBucketInventoryConfiguration / PutBucketInventoryConfiguration APIs\n\n## Notes\n- Inventory reports are written to a destination bucket (must have proper bucket policy)\n- Useful for large buckets where listing all objects is slow/expensive\n- Reports are generated asynchronously by AWS","status":"open","priority":4,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:04:38Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T13:04:38Z"}
{"id":"furman-vr5","title":"Update S3.md and README with missing features","description":"Document all undocumented S3 features: object lock, batch editing, anonymous access, sync enhancements, bandwidth limiting, provider database, STS role assumption, transfer acceleration, and additional bucket config features.","status":"closed","priority":2,"issue_type":"task","owner":"fenio@debian.org","created_at":"2026-02-26T20:58:23Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T21:00:06Z","closed_at":"2026-02-26T21:00:06Z","close_reason":"Closed"}
{"id":"furman-xq6","title":"Add S3 Access Points management","description":"Allow creating and managing S3 Access Points. No desktop S3 client currently offers this.\n\n## Scope\n- List access points for a bucket\n- Create new access points with name, VPC configuration, and policy\n- View/edit access point policies\n- Delete access points\n- Connect to a bucket via an access point ARN\n\n## Backend\n- New Tauri commands using S3 Control API: s3_list_access_points, s3_create_access_point, s3_get_access_point, s3_delete_access_point, s3_get_access_point_policy, s3_put_access_point_policy\n- Uses aws-sdk-s3control crate\n\n## Notes\n- Access Points simplify managing data access at scale\n- Each access point has its own DNS name and access policy\n- Can restrict access to specific VPCs\n- Requires aws-sdk-s3control as a new dependency","status":"open","priority":4,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T13:04:42Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T13:04:42Z"}
{"id":"furman-zjp","title":"Add S3 Object Lock support (retention and legal hold)","description":"Implement S3 Object Lock management -- a strong differentiator since only S3 Browser has full support among desktop clients. Object Lock is critical for compliance-focused users (WORM storage, SEC Rule 17a-4, HIPAA).\n\n## Bucket-level\n- Enable Object Lock at bucket creation time (cannot be added after)\n- Configure default retention mode (Governance / Compliance) and period\n- Display Object Lock status in bucket properties\n\n## Object-level\n- View retention mode, retain-until date, and legal hold status in object properties\n- Set/update retention on individual objects\n- Place/remove legal hold on objects\n- Batch update retention settings for multiple selected objects\n\n## Backend\n- New Tauri commands: s3_get_object_lock_configuration, s3_put_object_lock_configuration, s3_get_object_retention, s3_put_object_retention, s3_get_object_legal_hold, s3_put_object_legal_hold\n- New service functions in s3/service.rs\n\n## Notes\n- Object Lock requires versioning to be enabled\n- Compliance mode retention cannot be shortened or removed by any user, including root\n- Governance mode can be bypassed with s3:BypassGovernanceRetention permission","status":"closed","priority":2,"issue_type":"feature","owner":"fenio@debian.org","created_at":"2026-02-26T12:58:41Z","created_by":"Bartosz Fenski","updated_at":"2026-02-26T18:44:24Z","closed_at":"2026-02-26T18:44:24Z","close_reason":"Full implementation committed: 7 backend commands, 7 frontend service functions, Object Lock tab in properties dialog, 5 integration tests"}
